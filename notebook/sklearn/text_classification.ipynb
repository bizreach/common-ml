{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Tensor SkFlow: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/text_classification.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pandas\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers, Chain\n",
    "from commonml.sklearn import ChainerEstimator, SoftmaxCrossEntropyClassifier, RnnEstimator\n",
    "from commonml.text import VocabularyTransformer\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloads, unpacks and reads DBpedia dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbpedia = learn.datasets.load_dataset('dbpedia')\n",
    "X_train, y_train = pandas.DataFrame(dbpedia.train.data)[1], pandas.Series(dbpedia.train.target)\n",
    "X_test, y_test = pandas.DataFrame(dbpedia.test.data)[1], pandas.Series(dbpedia.test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_DOCUMENT_LENGTH = 10\n",
    "\n",
    "vocab_transformer = VocabularyTransformer(MAX_DOCUMENT_LENGTH)\n",
    "X_train_idx = np.array(list(vocab_transformer.fit_transform(X_train)))\n",
    "X_test_idx = np.array(list(vocab_transformer.transform(X_test)))\n",
    "\n",
    "n_words = len(vocab_transformer.get_feature_names())\n",
    "print('Total words: %d' % n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "class RNNModel(Chain):\n",
    "\n",
    "    def __init__(self, n_words, n_units, n_classes):\n",
    "        super(RNNModel, self).__init__(embed=F.EmbedID(n_words, n_units),\n",
    "                                       l1=L.LSTM(n_units, n_units),\n",
    "                                       l2=L.Linear(n_units, n_classes),\n",
    "                                      )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h0 = self.embed(x)\n",
    "        h1 = self.l1(h0)\n",
    "        h2 = self.l2(h1)\n",
    "        return h2\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.l1.reset_state()\n",
    "\n",
    "classifier = RnnEstimator(model=SoftmaxCrossEntropyClassifier(RNNModel(n_words, EMBEDDING_SIZE, 15)),\n",
    "                          optimizer=optimizers.Adam(),\n",
    "                          batch_size=1000,\n",
    "                          gpu=0,\n",
    "                          n_epoch=1)\n",
    "classifier.fit(X_train_idx, y_train)\n",
    "score = metrics.accuracy_score(y_test, classifier.predict(X_test_idx))\n",
    "print('Accuracy: {0:f}'.format(score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
